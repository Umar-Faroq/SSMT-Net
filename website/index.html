<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Leveraging Vision-Language Foundation Models in Medical Imaging</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-content">
                <h1 class="title">Leveraging Vision-Language Foundation Models to Reveal Hidden Image-Attribute Relationships in Medical Imaging</h1>
                <div class="authors">
                    <div class="author">
                        <span><a href="https://amarkr1.github.io/" target="_blank">Amar Kumar</a><sup>*</sup></span>
                        <span class="affiliations">McGill University, MILA-Quebec AI Institute</span>
                    </div>
                    <div class="author">
                        <span><a href="https://www.cim.mcgill.ca/~anitakriz/" target="_blank">Anita Kriz</a><sup>*</sup></span>
                        <span class="affiliations">McGill University, MILA-Quebec AI Institute</span>
                    </div>
                    <div class="author">
                        <span><a href="#" >Barak Pertzov</a></span>
                        <span class="affiliations">McMaster University</span>
                    </div>
                    <div class="author">
                        <span><a href="https://www.cim.mcgill.ca/~arbel/#" target="_blank">Tal Arbel</a></span>
                        <span class="affiliations">McGill University, MILA-Quebec AI Institute</span>
                    </div>
                </div>
                <div class="equal-contribution">
                    <span><sup>*</sup>Equal contribution</span>
                </div>
                <div class="publication-info">
                    <span>Accepted @<a href="https://sites.google.com/view/miv-cvpr2025/accepted-papers?authuser=0" target="_blank">MIV-CVPR</a> Workshop Proceedings 2025</span>
                </div>
            </div>
        </div>
    </header>

    <div class="container">
        <div class="two-column">
            <main>
                <section class="abstract">
                    <h2>Abstract</h2>
                    <p>Vision-language foundation models (VLMs) have shown impressive performance in guiding image generation through text, with emerging applications in medical imaging. In this work, we are the first to investigate the question: 'Can fine-tuned foundation models help identify critical, and possibly unknown, data properties?' By evaluating our proposed method on a chest x-ray dataset, we show that these models can generate high-resolution, precisely edited images compared to methods that rely on Structural Causal Models (SCMs) according to numerous metrics. For the first time, we demonstrate that fine-tuned VLMs can reveal hidden data relationships that were previously obscured due to available metadata granularity and model capacity limitations. Our experiments demonstrate both the potential of these models to reveal underlying dataset properties while also exposing the limitations of fine-tuned VLMs for accurate image editing and susceptibility to biases and spurious correlations.</p>
                </section>

                <section class="content-section" id="introduction">
                    <h2>1. Introduction</h2>
                    <p>Dataset biases present a significant challenge in the development of trustworthy machine learning models in healthcare applications. These biases can manifest as spurious correlations – misleading patterns between attributes of the data – which cause the model to learn incorrect associations that do not reflect true clinical relationships. For instance, algorithms trained on chest X-ray learned to classify pneumothorax based on the presence of a chest drain, which is inserted after pneumothorax diagnosis to treat it, and thus does not reflect the true pathological disease markers.</p>
                    <p>Causal-based approaches aim to answer causal queries and consequentially overcome challenges with spurious correlations by explicitly enforcing attribute relationships within a causal framework. These methods incorporate causal principles by embedding Structural Causal Models (SCMs) into the generation process and adhering to Pearl's Causal Hierarchy Theorem (CHT) to generate results. However, many SCM-based methods still require external classifiers to function effectively. Moreover, despite their theoretical rigor, the assumptions these methods require for theoretical validity often become unrealistic in real-world applications.</p>
                    <p>Foundation models, trained on vast and diverse datasets, have demonstrated remarkable generative capabilities in both computer vision and medical imaging. Two significant breakthroughs are particularly relevant: (i) enhanced image generation capabilities that enables the generation of unprecedented high-resolution images, and (ii) precise targeted editing of specific image attributes.</p>
                    <p>In this work, we explore the strengths and limitations of fine-tuned VLMs in generating high-resolution, realistic medical images while analyzing their dependence on, and ability to reveal, underlying dataset properties.</p>

                    <div class="figure">
                        <img src="images/intro.png" alt="Comparison of counterfactual generation">
                        <div class="figure-caption">Comparison of counterfactual generation in the SOTA structural causal model (SCM) and a foundation vision-language model. </div>
                    </div>
                </section>

                <section class="content-section" id="methodology">
                    <h2>2. Methodology</h2>
                    
                    <h3>2.1 Background</h3>
                    <p>Structural Causal Models & Counterfactual Generation: Our work investigates how fine-tuned vision-language foundation models can generate high-resolution, faithful counterfactual images. We discuss counterfactual generation using Structural Causal Models (SCMs) to provide context. These SCMs enable counterfactual reasoning for answering questions such as: What would image X look like if attribute Ai = a had instead been Ai = a′?</p>
                    <p>Stable Diffusion, our chosen generative model for counterfactual generation, is comprised of four components: (i) an Image encoder that transforms input images into low-dimensional latent representations; (ii) a CLIP text encoder that provides text conditioning to guide generation; (iii) a U-net denoiser that forms the core of the reverse diffusion process; and (iv) an Image decoder that converts denoised latents back to the original image space.</p>
                    
                    <h3>2.2 Training & Inference using Stable Diffusion</h3>
                    <p>Unlike SCM-based approaches that explicitly enforce causal relationships through predefined graphs, our method operates without imposing assumptions about attribute dependencies. We leverage language-guidance as our conditioning mechanism by converting attribute labels into textual descriptions.</p>
                    <p>During inference, generating counterfactual medical images with the fine-tuned model is easily accomplished through a slight modification of the text prompt in a zero-shot manner. In line with interventions in Structural Causal Models (SCMs), counterfactual image generation only requires specifying the attributes we explicitly wish to change.</p>
                    
                    <h3>2.3 Evaluation of Synthesized Counterfactuals</h3>
                    <p>We aim to validate the effectiveness of our method based on several key criteria: (i) Precision in High-Fidelity Counterfactual Image Editing; (ii) Comparison with SOTA SCM methods; and (iii) Unveiling Hidden Data Patterns.</p>
                    <p>For quantitative evaluation, we use metrics such as Perceptual Similarity, Identity Preservation, and Effectiveness to ensure that CF images meet key criteria.</p>
                </section>

                <section class="content-section" id="experiments">
                    <h2>3. Results</h2>
                    
                    
                    <p>Our high-resolution results not only align with the baseline method to what interventions in the image should be made, but also maintain high fidelity to the original image. The baseline method's pre-defined SCM includes an edge between age and pleural effusion, suggesting a potential causal relationship. Interestingly, without the need for an explicit SCM, the fine-tuned VLM also demonstrates an effect on pleural effusion when age is modified.</p>
                    
                    <div class="figure">
                        <img src="images/qual_results.jpg" alt="Counterfactual image generation results">
                        <div class="figure-caption">Comparison of counterfactual image generation results using our proposed method vs. baseline, a SOTA method that employs an explicit SCM for generation.</div>
                    </div>
                    
                    <p>Notably, the fine-tuned vision-language model associates cardiomegaly specifically with pacemakers when applying prompt-based modifications. This is evident when prompting the model to remove cardiomegaly, as it also removes the pacemaker. This relationship is supported by the literature, which indicates a bidirectional relationship between cardiomegaly and pacemaker implantation.</p>
                    
                    <div class="figure">
                        <img src="images/multiple_interv.jpg" alt="Revealing hidden image-attribute relationships">
                        <div class="figure-caption">Revealing hidden image-attribute relationships from prompt modifications. Notably, removing cardiomegaly also results in the specific removal of the pacemaker, but not other support devices, suggesting a hidden correlation in the training data.</div>
                    </div>
                    
                    
                </section>

                <section class="content-section conclusion" id="conclusion">
                    <h2>4. Conclusion</h2>
                    <p>Our work highlights the potential of fine-tuned vision-language foundation models in identifying critical data biases and spurious correlations. By leveraging their ability to generate high-resolution, precisely edited images through language prompts, these models reveal hidden data patterns that were previously undetectable. This has significant implications for the development of VLM-based methods in healthcare, where understanding dataset biases is crucial for building robust, trustworthy, and clinically deployable models. Our findings also underscore the limitations of fine-tuned VLMs, including their susceptibility to spurious correlations. Future work will focus on integrating causal reasoning to mitigate the reliance on biases and enhance the reliability of these models in clinical applications.</p>
                </section>
            </main>
            
            <aside>
                <div class="navigation">
                    <h3>Contents</h3>
                    <ul>
                        <li><a href="#introduction">1. Introduction</a></li>
                        <li><a href="#methodology">2. Methodology</a></li>
                        <li><a href="#experiments">3. Results</a></li>
                        <li><a href="#conclusion">4. Conclusion</a></li>
                    </ul>
                </div>
                
                
                
                <a href="#" class="btn">Access Paper</a>
            </aside>
        </div>
    </div>
    
    <footer>
        <div class="container">
            
            <div class="acknowledgements">
                <h3>Acknowledgments and Funding</h3>
                <p>The authors are grateful for funding provided by the Natural Sciences and Engineering Research Council of Canada, the Canadian Institute for Advanced Research (CIFAR) Artificial Intelligence Chairs program, Mila - Quebec AI Institute, Google Research, Calcul Québec, Fonds de recherche du Québec (FRQNT), and the Digital Research Alliance of Canada.</p>
            </div>
        </div>
        <p></p>
        <p>© Amar Kumar, Anita Kriz | 2025 MIV-CVPR Workshop Proceedings</p>
        <div class="container">
            <div class="footer-content">
                <div class="visitor-counter">
                    <span id="visitor-count">Loading...</span> visitors to this page
                </div>
            </div>
        </div>
    </footer>

    <script src="script.js"></script>

    <!-- Visitor Counter Script -->
    <script>
    // Wait for the DOM to be fully loaded
    document.addEventListener('DOMContentLoaded', function() {
    // Get the counter element
    const counterElement = document.getElementById('visitor-count');
    
    // Cloudflare Worker URL - our deployed worker
    const workerBaseUrl = 'https://vlm4hiar.amar-kumar.workers.dev';
    
    // Function to update the display with count
    function updateCounterDisplay(count) {
        if (counterElement) {
            counterElement.textContent = count.toLocaleString();
        }
    }
    
    // Function to handle errors
    function handleError(error) {
        console.error('Error with visitor counter:', error);
        // If error occurs, show a default value
        if (counterElement) {
            counterElement.textContent = '1+';
        }
    }
    
    try {
        // Always call the increment endpoint - the worker will handle uniqueness by IP
        fetch(`${workerBaseUrl}/increment`)
            .then(response => {
                if (!response.ok) {
                    throw new Error('Network response was not ok');
                }
                return response.json();
            })
            .then(data => {
                updateCounterDisplay(data.count);
            })
            .catch(handleError);
    } catch (error) {
        handleError(error);
    }
    });
    </script>
</body>
</html>
